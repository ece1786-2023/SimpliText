{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w4QZ0CCA4yZ",
        "outputId": "1e6b39b9-3818-455b-c092-45e3ce9ddb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (6.1.3)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.0.7)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (2023.10.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.12)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq\n",
        "from wordfreq import word_frequency\n",
        "import spacy\n",
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='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')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_sentences(statement):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Explain the following sentences. Only give me your explanation in a paragraph. Do not involve original sentences: {statement}\",\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        top_p=0.5,\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "tadY-rixBIVU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def examples(sentence):\n",
        "    completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": f\"Add one concise sentence of example if it has, to {sentence} for better understanding. Give me the sentences after adding this example.\"}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "sJhHQi5IBRF7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_freq(sentence):\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  words = [tok.lemma_ for tok in nlp(sentence) if tok.pos_ not in [\"PUNCT\", \"SPACE\"]]\n",
        "\n",
        "  freq_dict = {}\n",
        "  for word in words:\n",
        "    freq = word_frequency(word, 'en')\n",
        "    freq_dict[word] = freq\n",
        "\n",
        "  vocab = dict(sorted(freq_dict.items(), key=lambda item: item[1]))\n",
        "  return vocab\n",
        "\n",
        "def words_exp(sentence):\n",
        "\n",
        "  freq_dict = check_freq(sentence)\n",
        "\n",
        "  explain = dict((k, v) for k, v in freq_dict.items() if v < 1e-4)\n",
        "\n",
        "  words = list(explain.keys())\n",
        "\n",
        "  return words\n",
        "\n",
        "def explain_words(sentence):\n",
        "  words = words_exp(sentence)\n",
        "  assis = 'Give me a new verison of sentences which correctly explain these words in simpler sentences or correctly paraphrase with super easy-to-understand words(consider their academic meaning if neccesary):'\n",
        "  for word in words:\n",
        "    assis += word\n",
        "    assis += ', '\n",
        "  assis += 'inside sentences and only give me the new version of explained sentences.'\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "         {\"role\": \"system\",\n",
        "         \"content\": assis},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": sentence}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5,\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "SjJoTUKmBbTl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simplify_structure(sentence):\n",
        "  completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"Break all sentences into simple sentences without missing any important details and ensure the sentences are readable and coherent. Also do not increase words' complexity, do not give me several points but a coherent paragraph.\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": sentence}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5,\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "hI71hCY8BlMW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain(sent):\n",
        "  tmp = explain_sentences(sent)\n",
        "  tmp2 = examples(tmp)\n",
        "  tmp3 = explain_words(tmp2)\n",
        "  tmp4 = simplify_structure(tmp3)\n",
        "  result = explain_words(tmp4)\n",
        "  return result"
      ],
      "metadata": {
        "id": "wZrgUVJPB2Ed"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explain(\"However, Edwards believes the small changes in solar heating produced by Milankovitch cycles are then amplified by feedback mechanisms on Earth.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "xTPof6ACB_2J",
        "outputId": "f8c1a170-d9c5-428c-be2d-e229946f99d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Edwards thinks that tiny shifts in the warmth from the sun happen because of big patterns in space called Milankovitch cycles. These cycles have to do with how Earth moves in space. Other things make these effects stronger on Earth's climate. For instance, when the sun gets hotter, a process starts where the extra heat makes more heat happen. This process makes ice turn into water. When there's less ice, Earth doesn't bounce back as much sunlight. This is called having a lower albedo. When Earth has a lower albedo, it gets even warmer. More warmth means more ice turns into water. These processes can either add to or reduce the effect. They include ice, air gases, and ocean movements. These processes make the original change from the sun's warmth even bigger. So, they end up changing the climate more than just the space patterns would on their own.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explain(\"Ehrlich's model shows that whilst most of these oscillations cancel each other out, some reinforce one another and become long-lived temperature variations.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "6Ag6RfZxERx_",
        "outputId": "25796448-4901-4730-eb0a-a29a990973f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ehrlich's concept says that ups and downs happen in a system. These ups and downs might be linked to how warm or cold it gets. Often, many ups and downs happen at the same time. Usually, they even out so no single up or down takes over for a really long time. But Ehrlich's concept also shows that sometimes these ups and downs can get stronger together. When they get stronger, they don't even out. Instead, they keep going and cause longer changes in how warm or cold it is. This keeping going might point to a special part of the system that makes certain ups and downs get bigger and more regular. For example, if sea warmth patterns like El Niño happen at the same time as the big ten-year sea pattern in the Pacific at their strongest points, they might work together to make strange weather last longer. This weather could be long dry times or really big storms.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')\n",
        "df = df.reset_index(drop=True)\n",
        "original = df[df.columns[0]].tolist()\n",
        "results = []\n",
        "for statement in original:\n",
        "    exp = explain(statement)\n",
        "    results.append(exp)\n",
        "\n",
        "df_combined = pd.DataFrame({\n",
        "    'OriginalStatements': original,\n",
        "    'ExplainedStatements': results,\n",
        "})\n",
        "\n",
        "df_combined.to_csv('explanation.csv', index=False)"
      ],
      "metadata": {
        "id": "YUg-HOp8F9dG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b0f4df2e-4055-445a-e135-2c2c0aa0aa77"
      },
      "execution_count": 9
}
