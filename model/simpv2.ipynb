{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X1orK9xGpQ7b"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Set your API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Define the functions for each task\n",
        "def simplify(statement):\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Simplify the following sentences: {statement}\",\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        top_p=0.5,\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordfreq\n",
        "from wordfreq import word_frequency\n",
        "import spacy\n",
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='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')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mF-6Ss2rFHU",
        "outputId": "096e7678-0c6c-4a16-94ce-1a196437a19c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordfreq\n",
            "  Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy>=6.1 (from wordfreq)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.3.0)\n",
            "Collecting locate<2.0.0,>=1.1.1 (from wordfreq)\n",
            "  Downloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.0.7)\n",
            "Collecting regex>=2023.10.3 (from wordfreq)\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.12)\n",
            "Installing collected packages: regex, locate, ftfy, wordfreq\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.6.3\n",
            "    Uninstalling regex-2023.6.3:\n",
            "      Successfully uninstalled regex-2023.6.3\n",
            "Successfully installed ftfy-6.1.3 locate-1.1.1 regex-2023.10.3 wordfreq-3.1.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_freq(sentence):\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  words = [tok.lemma_ for tok in nlp(sentence) if tok.pos_ not in [\"PUNCT\", \"SPACE\"]]\n",
        "\n",
        "  freq_dict = {}\n",
        "  for word in words:\n",
        "    freq = word_frequency(word, 'en')\n",
        "    freq_dict[word] = freq\n",
        "\n",
        "  vocab = dict(sorted(freq_dict.items(), key=lambda item: item[1]))\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "UKBRWkvlrLhV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words_exp(sentence):\n",
        "\n",
        "  freq_dict = check_freq(sentence)\n",
        "\n",
        "  explain = dict((k, v) for k, v in freq_dict.items() if v < 1e-4)\n",
        "\n",
        "  words = list(explain.keys())\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "eTIpPl18rMVe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simplify_words(sentence):\n",
        "  words = words_exp(sentence)\n",
        "  assis = 'Give me a new verison of sentences which replace these words in simpler synonyms or explanations:'\n",
        "  for word in words:\n",
        "    assis += word\n",
        "    assis += ', '\n",
        "  assis += 'inside sentences and only give me the new version of explained sentences. Please combine with orginal sentence meanings and keep the original meanings.'\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "         {\"role\": \"system\",\n",
        "         \"content\": assis},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": sentence}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5,\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "VIPcDtajrOWh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simplify_structure(sentence):\n",
        "  completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"Break sentence into shorter, simpler sentences without increasing words complexity, without changing sentence's meanings.\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": sentence}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5,\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "tgD-GJbgriqL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output(sentence):\n",
        "    tmp = simplify(sentence)\n",
        "    tmp2 = simplify_words(tmp)\n",
        "    tmp3 = simplify_structure(tmp2)\n",
        "    tmp4 = simplify_words(tmp3)\n",
        "    output = simplify_structure(tmp4)\n",
        "    return output\n",
        ""
      ],
      "metadata": {
        "id": "2MnOWN5ur2Cm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output(\"If Dickens’s prose fiction has “defects”—excesses of melodrama, sentimentality, contrived plots, and manufactured happy endings—these are the defects of his era, which for all his greatness Dickens had not the rebellious spirit to resist; he was at heart a crowd-pleaser, a theatrical entertainer, with no interest in subverting the conventions of the novel as his great successors D.H. Lawrence, James Joyce, and Virginia Woolf would have; nor did he contemplate the subtle and ironic counterminings of human relations in the way of George Eliot and Thomas Hardy, who brought to the English novel an element of nuanced psychological realism not previously explored.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "5-dSd2gwsJdu",
        "outputId": "2b3df6ca-0da3-4069-9d57-15575a58fd59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Charles Dickens's writing has flaws. It includes overly dramatic sections. It also has predictable happy endings. However, these flaws were common in his time. Unlike later writers such as D.H. Lawrence, James Joyce, and Virginia Woolf, Dickens did not challenge traditional storytelling. He did not explore personal relationships deeply. George Eliot and Thomas Hardy did this. They showed a deep understanding of the human mind in their work. Dickens aimed to entertain many people.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output(\"After the stealth virus infects the tumour, it replicates, but the copies do not have the chemical modifications.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7ehumPinwDYf",
        "outputId": "aa817a34-2c61-4fcf-e728-ed05b01563e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The tricky virus enters the growth. Inside, it replicates itself. But the new copies lack changes in their substances.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')\n",
        "df = df.reset_index(drop=True)\n",
        "original = df[df.columns[0]].tolist()\n",
        "results = []\n",
        "for statement in original:\n",
        "    simplified = output(statement)\n",
        "    results.append(simplified)\n",
        "\n",
        "df_combined = pd.DataFrame({\n",
        "    'OriginalStatements': original,\n",
        "    'SimplifiedStatements': results,\n",
        "})\n",
        "\n",
        "\n",
        "df_combined.to_csv('simplification.csv', index=False)"
      ],
      "metadata": {
        "id": "GmOeuubIyLde"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}